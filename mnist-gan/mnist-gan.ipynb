{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccaeccf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 18:33:26.775839: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-15 18:33:26.775871: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ccc0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers \n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14552173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "11501568/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8ad7809",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a1322bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f89d6057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 18:37:34.559226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 18:37:34.560767: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-15 18:37:34.561069: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-15 18:37:34.561322: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-15 18:37:34.561553: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2021-12-15 18:37:34.561788: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2021-12-15 18:37:34.562019: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-15 18:37:34.562248: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-15 18:37:34.562477: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-12-15 18:37:34.562517: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-12-15 18:37:34.565616: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b86d5f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c6aa829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9a10347550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57e3f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66fd35de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00185913]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4afeed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2ae5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b9c206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03f0ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d4e6c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(\n",
    "    generator_optimizer=generator_optimizer,\n",
    "    discriminator_optimizer=discriminator_optimizer,\n",
    "    generator=generator,\n",
    "    discriminator=discriminator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcde1760",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10028a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5502cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(\n",
    "        generator,\n",
    "        epochs,\n",
    "        seed\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30e913ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ae26408",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28118/2228458018.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_28118/4180226733.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97971c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08951c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef7d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff9c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = 'dcgan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  for filename in filenames:\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61e26a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ce564f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
